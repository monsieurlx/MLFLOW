{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('application_train.csv')\n",
    "dftest = pd.read_csv('application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SK_ID_CURR\n",
      "TARGET\n",
      "NAME_CONTRACT_TYPE\n",
      "CODE_GENDER\n",
      "FLAG_OWN_CAR\n",
      "FLAG_OWN_REALTY\n",
      "CNT_CHILDREN\n",
      "AMT_INCOME_TOTAL\n",
      "AMT_CREDIT\n",
      "AMT_ANNUITY\n",
      "AMT_GOODS_PRICE\n",
      "NAME_TYPE_SUITE\n",
      "NAME_INCOME_TYPE\n",
      "NAME_EDUCATION_TYPE\n",
      "NAME_FAMILY_STATUS\n",
      "NAME_HOUSING_TYPE\n",
      "REGION_POPULATION_RELATIVE\n",
      "DAYS_BIRTH\n",
      "DAYS_EMPLOYED\n",
      "DAYS_REGISTRATION\n",
      "DAYS_ID_PUBLISH\n",
      "OWN_CAR_AGE\n",
      "FLAG_MOBIL\n",
      "FLAG_EMP_PHONE\n",
      "FLAG_WORK_PHONE\n",
      "FLAG_CONT_MOBILE\n",
      "FLAG_PHONE\n",
      "FLAG_EMAIL\n",
      "OCCUPATION_TYPE\n",
      "CNT_FAM_MEMBERS\n",
      "REGION_RATING_CLIENT\n",
      "REGION_RATING_CLIENT_W_CITY\n",
      "WEEKDAY_APPR_PROCESS_START\n",
      "HOUR_APPR_PROCESS_START\n",
      "REG_REGION_NOT_LIVE_REGION\n",
      "REG_REGION_NOT_WORK_REGION\n",
      "LIVE_REGION_NOT_WORK_REGION\n",
      "REG_CITY_NOT_LIVE_CITY\n",
      "REG_CITY_NOT_WORK_CITY\n",
      "LIVE_CITY_NOT_WORK_CITY\n",
      "ORGANIZATION_TYPE\n",
      "EXT_SOURCE_1\n",
      "EXT_SOURCE_2\n",
      "EXT_SOURCE_3\n",
      "APARTMENTS_AVG\n",
      "BASEMENTAREA_AVG\n",
      "YEARS_BEGINEXPLUATATION_AVG\n",
      "YEARS_BUILD_AVG\n",
      "COMMONAREA_AVG\n",
      "ELEVATORS_AVG\n",
      "ENTRANCES_AVG\n",
      "FLOORSMAX_AVG\n",
      "FLOORSMIN_AVG\n",
      "LANDAREA_AVG\n",
      "LIVINGAPARTMENTS_AVG\n",
      "LIVINGAREA_AVG\n",
      "NONLIVINGAPARTMENTS_AVG\n",
      "NONLIVINGAREA_AVG\n",
      "APARTMENTS_MODE\n",
      "BASEMENTAREA_MODE\n",
      "YEARS_BEGINEXPLUATATION_MODE\n",
      "YEARS_BUILD_MODE\n",
      "COMMONAREA_MODE\n",
      "ELEVATORS_MODE\n",
      "ENTRANCES_MODE\n",
      "FLOORSMAX_MODE\n",
      "FLOORSMIN_MODE\n",
      "LANDAREA_MODE\n",
      "LIVINGAPARTMENTS_MODE\n",
      "LIVINGAREA_MODE\n",
      "NONLIVINGAPARTMENTS_MODE\n",
      "NONLIVINGAREA_MODE\n",
      "APARTMENTS_MEDI\n",
      "BASEMENTAREA_MEDI\n",
      "YEARS_BEGINEXPLUATATION_MEDI\n",
      "YEARS_BUILD_MEDI\n",
      "COMMONAREA_MEDI\n",
      "ELEVATORS_MEDI\n",
      "ENTRANCES_MEDI\n",
      "FLOORSMAX_MEDI\n",
      "FLOORSMIN_MEDI\n",
      "LANDAREA_MEDI\n",
      "LIVINGAPARTMENTS_MEDI\n",
      "LIVINGAREA_MEDI\n",
      "NONLIVINGAPARTMENTS_MEDI\n",
      "NONLIVINGAREA_MEDI\n",
      "FONDKAPREMONT_MODE\n",
      "HOUSETYPE_MODE\n",
      "TOTALAREA_MODE\n",
      "WALLSMATERIAL_MODE\n",
      "EMERGENCYSTATE_MODE\n",
      "OBS_30_CNT_SOCIAL_CIRCLE\n",
      "DEF_30_CNT_SOCIAL_CIRCLE\n",
      "OBS_60_CNT_SOCIAL_CIRCLE\n",
      "DEF_60_CNT_SOCIAL_CIRCLE\n",
      "DAYS_LAST_PHONE_CHANGE\n",
      "FLAG_DOCUMENT_2\n",
      "FLAG_DOCUMENT_3\n",
      "FLAG_DOCUMENT_4\n",
      "FLAG_DOCUMENT_5\n",
      "FLAG_DOCUMENT_6\n",
      "FLAG_DOCUMENT_7\n",
      "FLAG_DOCUMENT_8\n",
      "FLAG_DOCUMENT_9\n",
      "FLAG_DOCUMENT_10\n",
      "FLAG_DOCUMENT_11\n",
      "FLAG_DOCUMENT_12\n",
      "FLAG_DOCUMENT_13\n",
      "FLAG_DOCUMENT_14\n",
      "FLAG_DOCUMENT_15\n",
      "FLAG_DOCUMENT_16\n",
      "FLAG_DOCUMENT_17\n",
      "FLAG_DOCUMENT_18\n",
      "FLAG_DOCUMENT_19\n",
      "FLAG_DOCUMENT_20\n",
      "FLAG_DOCUMENT_21\n",
      "AMT_REQ_CREDIT_BUREAU_HOUR\n",
      "AMT_REQ_CREDIT_BUREAU_DAY\n",
      "AMT_REQ_CREDIT_BUREAU_WEEK\n",
      "AMT_REQ_CREDIT_BUREAU_MON\n",
      "AMT_REQ_CREDIT_BUREAU_QRT\n",
      "AMT_REQ_CREDIT_BUREAU_YEAR\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns: \n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns.drop(list(df.filter(regex='FLAG_DOCUMENT_')))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_data(df):\n",
    "    total = df.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (df.isnull().sum()/df.isnull().count()*100).sort_values(ascending = False)\n",
    "    percent = round(percent,2)\n",
    "    missing_df  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    print( missing_df.head(102))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Total  Percent\n",
      "COMMONAREA_MEDI           214865    69.87\n",
      "COMMONAREA_AVG            214865    69.87\n",
      "COMMONAREA_MODE           214865    69.87\n",
      "NONLIVINGAPARTMENTS_MODE  213514    69.43\n",
      "NONLIVINGAPARTMENTS_AVG   213514    69.43\n",
      "...                          ...      ...\n",
      "FLAG_PHONE                     0     0.00\n",
      "FLAG_CONT_MOBILE               0     0.00\n",
      "FLAG_EMP_PHONE                 0     0.00\n",
      "FLAG_MOBIL                     0     0.00\n",
      "SK_ID_CURR                     0     0.00\n",
      "\n",
      "[102 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "get_missing_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#over 50% of missing data we clean it, can't be used \n",
    "df = df[df.columns.drop(list(df.filter(regex='APARTMENTS_')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='WALLSMATERIAL_')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='ELEVATORS_')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='NONLIVINGAREA_')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='ENTRANCES_')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='FLOORSMIN_')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='YEARS_BUILD_')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='FONDKAPREMONT_')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='OWN_CAR_AGE')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='HOUSETYPE_MODE ')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='EXT_SOURCE_1')))]\n",
    "df = df[df.columns.drop(list(df.filter(regex='HOUSETYPE_MODE')))]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = df.corr()['TARGET'].sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Positive Correlations:\n",
      " AMT_REQ_CREDIT_BUREAU_YEAR     0.019930\n",
      "FLAG_WORK_PHONE                0.028524\n",
      "DEF_60_CNT_SOCIAL_CIRCLE       0.031276\n",
      "DEF_30_CNT_SOCIAL_CIRCLE       0.032248\n",
      "LIVE_CITY_NOT_WORK_CITY        0.032518\n",
      "DAYS_REGISTRATION              0.041975\n",
      "REG_CITY_NOT_LIVE_CITY         0.044395\n",
      "FLAG_EMP_PHONE                 0.045982\n",
      "REG_CITY_NOT_WORK_CITY         0.050994\n",
      "DAYS_ID_PUBLISH                0.051457\n",
      "DAYS_LAST_PHONE_CHANGE         0.055218\n",
      "REGION_RATING_CLIENT           0.058899\n",
      "REGION_RATING_CLIENT_W_CITY    0.060893\n",
      "DAYS_BIRTH                     0.078239\n",
      "TARGET                         1.000000\n",
      "Name: TARGET, dtype: float64\n",
      "\n",
      "Most Negative Correlations:\n",
      " EXT_SOURCE_3                 -0.178919\n",
      "EXT_SOURCE_2                 -0.160472\n",
      "DAYS_EMPLOYED                -0.044932\n",
      "FLOORSMAX_AVG                -0.044003\n",
      "FLOORSMAX_MEDI               -0.043768\n",
      "FLOORSMAX_MODE               -0.043226\n",
      "AMT_GOODS_PRICE              -0.039645\n",
      "REGION_POPULATION_RELATIVE   -0.037227\n",
      "LIVINGAREA_AVG               -0.032997\n",
      "LIVINGAREA_MEDI              -0.032739\n",
      "TOTALAREA_MODE               -0.032596\n",
      "LIVINGAREA_MODE              -0.030685\n",
      "AMT_CREDIT                   -0.030369\n",
      "HOUR_APPR_PROCESS_START      -0.024166\n",
      "FLAG_PHONE                   -0.023806\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use the 10 features that has the most correlation with the target \n",
    "\n",
    "df1 = df[['DAYS_BIRTH', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT', 'DAYS_LAST_PHONE_CHANGE', 'DAYS_ID_PUBLISH', 'REG_CITY_NOT_WORK_CITY', 'FLAG_EMP_PHONE', 'REG_CITY_NOT_LIVE_CITY', 'DAYS_REGISTRATION', 'LIVE_CITY_NOT_WORK_CITY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>DAYS_LAST_PHONE_CHANGE</th>\n",
       "      <th>DAYS_ID_PUBLISH</th>\n",
       "      <th>REG_CITY_NOT_WORK_CITY</th>\n",
       "      <th>FLAG_EMP_PHONE</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>DAYS_REGISTRATION</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9461</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1134.0</td>\n",
       "      <td>-2120</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-3648.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-16765</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-828.0</td>\n",
       "      <td>-291</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1186.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19046</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>-2531</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4260.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-19005</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-617.0</td>\n",
       "      <td>-2437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-9833.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-19932</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1106.0</td>\n",
       "      <td>-3458</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-4311.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DAYS_BIRTH  REGION_RATING_CLIENT_W_CITY  REGION_RATING_CLIENT  \\\n",
       "0       -9461                            2                     2   \n",
       "1      -16765                            1                     1   \n",
       "2      -19046                            2                     2   \n",
       "3      -19005                            2                     2   \n",
       "4      -19932                            2                     2   \n",
       "\n",
       "   DAYS_LAST_PHONE_CHANGE  DAYS_ID_PUBLISH  REG_CITY_NOT_WORK_CITY  \\\n",
       "0                 -1134.0            -2120                       0   \n",
       "1                  -828.0             -291                       0   \n",
       "2                  -815.0            -2531                       0   \n",
       "3                  -617.0            -2437                       0   \n",
       "4                 -1106.0            -3458                       1   \n",
       "\n",
       "   FLAG_EMP_PHONE  REG_CITY_NOT_LIVE_CITY  DAYS_REGISTRATION  \\\n",
       "0               1                       0            -3648.0   \n",
       "1               1                       0            -1186.0   \n",
       "2               1                       0            -4260.0   \n",
       "3               1                       0            -9833.0   \n",
       "4               1                       0            -4311.0   \n",
       "\n",
       "   LIVE_CITY_NOT_WORK_CITY  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We now have cleaned data let's try to train our models : Xgboost, Random Forest and Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the data by replacing NaN with zero\n",
    "df2 = np.nan_to_num(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest : \n",
    "\n",
    "#Prepare data\n",
    "#X = df2.iloc[:, 0:8].values\n",
    "#y = df2.iloc[:, 9].values\n",
    "X = df2[:, 0:8]\n",
    "y = df2[:, 9]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create test and validation set \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Gradient boosting \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#Xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_trains, X_tests, y_trains, y_tests = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation the model \n",
    "from sklearn import metrics\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(actual, pred))\n",
    "    mae = metrics.mean_absolute_error(actual, pred)\n",
    "    r2 = metrics.r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,estim, rand, **kwargs):  \n",
    "    with mlflow.start_run():\n",
    "    \n",
    "        lr = kwargs['lr']\n",
    "        mf = kwargs['mf']\n",
    "        dep = kwargs['dep']\n",
    "        \n",
    "        ##RANDOM FOREST\n",
    "    \n",
    "        if model == RandomForestRegressor:\n",
    "            \n",
    "            regressor = model(n_estimators=estim, random_state=rand)\n",
    "            regressor.fit(X_trains, y_trains)\n",
    "            y_pred = regressor.predict(X_tests)\n",
    "        \n",
    "            print(\"Elasticnet model (n_estimators=%f, random_state=%f):\" % (estim, rand))\n",
    "            m = regressor\n",
    "                        \n",
    "        ## GRADIENT BOOSTING \n",
    "            \n",
    "        elif model == GradientBoostingClassifier:\n",
    "            #evaluation of the model with the right learning rate \n",
    "          \n",
    "            \n",
    "            gb_clf2 = model(n_estimators=estim, learning_rate= lr, max_features=mf, max_depth=dep, random_state=rand)\n",
    "            gb_clf2.fit(X_trains, y_trains)\n",
    "            predictions = gb_clf2.predict(X_tests)\n",
    "            \n",
    "         # print(\"Confusion Matrix:\")\n",
    "         # print(confusion_matrix(y_tests, predictions))\n",
    "         # print(\"Classification Report\")\n",
    "         # print(classification_report(y_tests, predictions))\n",
    "            y_pred = gb_clf2.predict(X_tests)\n",
    "            m = gb_clf2\n",
    "            mlflow.log_param(\"max features\", mf)\n",
    "            mlflow.log_param(\"max depth\", rand)\n",
    "            mlflow.log_param(\"learning rate\", lr)\n",
    "        \n",
    "        \n",
    "        ## XG BOOST \n",
    "        \n",
    "        elif model == XGBClassifier:\n",
    "            \n",
    "            \n",
    "            #Training model \n",
    "            xgb_clf = model(n_estimators = estim ,random_state = rand, learning_rate = lr, max_depth = dep, max_features = mf)\n",
    "            xgb_clf.fit(X_trains, y_trains)\n",
    "            y_pred = xgb_clf.predict(X_tests)\n",
    "            m = xgb_clf\n",
    "        \n",
    "        \n",
    "            \n",
    "        (rmse, mae, r2) = eval_metrics(y_tests, y_pred)\n",
    "        # Print out metrics\n",
    "        print('Mean Absolute Error:', rmse)\n",
    "        print('Mean Squared Error:', mae)\n",
    "        print('Root Mean Squared Error:', r2)\n",
    "        # Log parameter, metrics, and model to MLflow\n",
    "        mlflow.log_param(\"n_estimators\", estim)\n",
    "        mlflow.log_param(\"random state\", rand)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "        \n",
    "        \n",
    "        mlflow.sklearn.log_model(m, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:12:17] WARNING: ../src/learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Mean Absolute Error: 0.11941301025377866\n",
      "Mean Squared Error: 0.014259467017869048\n",
      "Root Mean Squared Error: 0.9031413939746537\n"
     ]
    }
   ],
   "source": [
    "train(XGBClassifier,20,0,lr=0.5, mf = 2 , dep = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-10-26 08:57:56 +0100] [6514] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-10-26 08:57:56 +0100] [6514] [INFO] Listening at: http://127.0.0.1:5000 (6514)\n",
      "[2020-10-26 08:57:56 +0100] [6514] [INFO] Using worker: sync\n",
      "[2020-10-26 08:57:56 +0100] [6519] [INFO] Booting worker with pid: 6519\n",
      "^C\n",
      "[2020-10-26 09:07:39 +0100] [6514] [INFO] Handling signal: int\n",
      "[2020-10-26 09:07:39 +0100] [6519] [INFO] Worker exiting (pid: 6519)\n"
     ]
    }
   ],
   "source": [
    "#!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = df[df.columns.drop(list(df.filter(regex='FLAG_DOCUMENT_')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='APARTMENTS_')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='WALLSMATERIAL_')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='ELEVATORS_')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='NONLIVINGAREA_')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='ENTRANCES_')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='FLOORSMIN_')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='YEARS_BUILD_')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='OWN_CAR_AGE')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='HOUSETYPE_MODE ')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='EXT_SOURCE_1')))]\n",
    "dftest = df[df.columns.drop(list(df.filter(regex='HOUSETYPE_MODE')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest1 = df[['DAYS_BIRTH', 'REGION_RATING_CLIENT_W_CITY', 'REGION_RATING_CLIENT', 'DAYS_LAST_PHONE_CHANGE', 'DAYS_ID_PUBLISH', 'REG_CITY_NOT_WORK_CITY', 'FLAG_EMP_PHONE', 'REG_CITY_NOT_LIVE_CITY', 'DAYS_REGISTRATION', 'LIVE_CITY_NOT_WORK_CITY']]\n",
    "dftest2 = np.nan_to_num(dftest1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df2[:, 0:8]\n",
    "y_test = df2[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction \n",
    "y_pred = regressor.predict(X_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have low error value, great model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's choose a learning rate and train the model \n",
    "#lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "\n",
    "#for learning_rate in lr_list:\n",
    "    #gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)\n",
    "    #gb_clf.fit(X, y)\n",
    "\n",
    "   # print(\"Learning rate: \", learning_rate)\n",
    "    #print(\"Accuracy score (training): {0:.3f}\".format(gb_clf.score(X_trains, y_trains)))\n",
    "   # print(\"Accuracy score (validation): {0:.3f}\".format(gb_clf.score(X_tests, y_tests)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-de6425ea99c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# XAI with SHAP Method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xgb_clf' is not defined"
     ]
    }
   ],
   "source": [
    "# XAI with SHAP Method\n",
    "import shap\n",
    "shap_values = shap.TreeExplainer(xgb_clf).shap_values(X)\n",
    "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary plot \n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
